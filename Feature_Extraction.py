{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa700ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Bio\n",
    "#Merging_CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs\n",
    "csv1 = pd.read_csv(\"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/test_sequences_res_750.csv\")  # Replace with your actual file path\n",
    "csv2 = pd.read_csv(\"/content/drive/MyDrive/Ragini_SNP/Susceptibel_fna_dataset - merged/test_sequences_sus_750.csv\")\n",
    "# Merge them by rows\n",
    "merged_df = pd.concat([csv1, csv2], ignore_index=True)\n",
    "\n",
    "# Shuffle the merged DataFrame\n",
    "shuffled_df = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the final result\n",
    "shuffled_df.to_csv(\"/content/drive/MyDrive/Ragini_SNP/test_merged_4mer_final_dataset.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Merged and shuffled CSV saved as 'merged_shuffled.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a864b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# GC Content\n",
    "def gc_content(seq):\n",
    "    seq = seq.upper()\n",
    "    g = seq.count(\"G\")\n",
    "    c = seq.count(\"C\")\n",
    "    return 100 * (g + c) / len(seq) if len(seq) > 0 else 0\n",
    "\n",
    "# k-mer frequencies\n",
    "def kmer_frequencies(seq, k):\n",
    "    seq = seq.upper()\n",
    "    kmers = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "    total = len(kmers)\n",
    "    counts = Counter(kmers)\n",
    "\n",
    "    bases = \"ACGT\"\n",
    "    features = {}\n",
    "    for kmer in product(bases, repeat=k):\n",
    "        kmer_str = ''.join(kmer)\n",
    "        features[f\"{k}mer_{kmer_str}\"] = counts[kmer_str] / total if total > 0 else 0\n",
    "    return features\n",
    "\n",
    "# ORF features\n",
    "def extract_orf_features(seq):\n",
    "    seq = seq.upper()\n",
    "    start_codon = \"ATG\"\n",
    "    stop_codons = {\"TAA\", \"TAG\", \"TGA\"}\n",
    "    orfs = []\n",
    "\n",
    "    for frame in range(3):\n",
    "        i = frame\n",
    "        while i < len(seq) - 2:\n",
    "            codon = seq[i:i+3]\n",
    "            if codon == start_codon:\n",
    "                for j in range(i+3, len(seq) - 2, 3):\n",
    "                    stop = seq[j:j+3]\n",
    "                    if stop in stop_codons:\n",
    "                        orf = seq[i:j+3]\n",
    "                        if len(orf) >= 100:\n",
    "                            orfs.append(orf)\n",
    "                        break\n",
    "            i += 3\n",
    "\n",
    "    total_orf_bases = sum(len(orf) for orf in orfs)\n",
    "    longest_orf = max([len(orf) for orf in orfs], default=0)\n",
    "    orf_coverage = 100 * total_orf_bases / len(seq) if len(seq) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"orf_count\": len(orfs),\n",
    "        \"longest_orf\": longest_orf,\n",
    "        \"orf_coverage_percent\": orf_coverage\n",
    "    }\n",
    "\n",
    "# Main function to extract features from FASTA and save as CSV\n",
    "def extract_features_to_csv(fasta_file, output_csv):\n",
    "    feature_list = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq = str(record.seq).upper()\n",
    "        features = {\n",
    "            \"ID\": record.id,\n",
    "            \"GC_Content\": gc_content(seq),\n",
    "        }\n",
    "        features.update(kmer_frequencies(seq, 2))\n",
    "        features.update(kmer_frequencies(seq, 3))\n",
    "        features.update(kmer_frequencies(seq, 4))\n",
    "\n",
    "        features.update(extract_orf_features(seq))\n",
    "        feature_list.append(features)\n",
    "\n",
    "    df = pd.DataFrame(feature_list)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"âœ… Features saved to {output_csv}\")\n",
    "\n",
    "# Paths for your three FASTA input files\n",
    "fasta_train = \"/content/drive/MyDrive/Ragini_SNP/Susceptibel_fna_dataset - merged/train_sequences_sus_6000.fasta\"\n",
    "#fasta_val   = \"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/val_sequences_res_750.fasta\"\n",
    "#fasta_test  = \"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/test_sequences_res_750.fasta\"\n",
    "\n",
    "# Output CSVs\n",
    "output_train = \"/content/drive/MyDrive/Ragini_SNP/Susceptibel_fna_dataset - merged/train_features_sus_5mer_6000.csv\"\n",
    "#output_val   = \"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/val_features_res_750.csv\"\n",
    "#output_test  = \"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/test_features_res_750.csv\"\n",
    "\n",
    "# Process all three\n",
    "extract_features_to_csv(fasta_train, output_train)\n",
    "#extract_features_to_csv(fasta_val, output_val)\n",
    "#extract_features_to_csv(fasta_test, output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2628b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection using mRMR\n",
    "!pip install pymrmr\n",
    "import pandas as pd\n",
    "import pymrmr\n",
    "\n",
    "# ðŸ”¹ Load your dataset\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/train_features_res_6000.csv\")\n",
    "\n",
    "# ðŸ”¹ Ensure the 'Class' column is the first column\n",
    "columns = ['Class'] + [col for col in df.columns if col != 'Class']\n",
    "df = df[columns]\n",
    "\n",
    "# ðŸ”¹ Apply mRMR to select top k features (e.g., 10)\n",
    "selected_features = pymrmr.mRMR(df, 'MIQ', 10)  # Options: 'MIQ' or 'MID'\n",
    "print(\"Selected Features using mRMR:\", selected_features)\n",
    "\n",
    "# ðŸ”¹ Save selected features\n",
    "selected_df = df[['Class'] + selected_features]\n",
    "selected_df.to_csv(\"/content/drive/MyDrive/Ragini_SNP/Resistant_fna_dataset - merged/selected_features_res_train_mrmr_10.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81800d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "# GC Content\n",
    "def gc_content(seq):\n",
    "    seq = seq.upper()\n",
    "    g = seq.count(\"G\")\n",
    "    c = seq.count(\"C\")\n",
    "    return 100 * (g + c) / len(seq) if len(seq) > 0 else 0\n",
    "\n",
    "# k-mer frequencies (4-mer only for selected features)\n",
    "def selected_4mer_frequencies(seq):\n",
    "    seq = seq.upper()\n",
    "    k = 4\n",
    "    kmers = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "    total = len(kmers)\n",
    "    counts = Counter(kmers)\n",
    "\n",
    "    selected_kmers = ['GCCC', 'GCCG', 'GCAT', 'GCCA', 'GCAC', 'GATT']\n",
    "    features = {}\n",
    "    for kmer in selected_kmers:\n",
    "        features[f\"4mer_{kmer}\"] = counts[kmer] / total if total > 0 else 0\n",
    "    return features\n",
    "\n",
    "# ORF features\n",
    "def extract_orf_features(seq):\n",
    "    seq = seq.upper()\n",
    "    start_codon = \"ATG\"\n",
    "    stop_codons = {\"TAA\", \"TAG\", \"TGA\"}\n",
    "    orfs = []\n",
    "\n",
    "    for frame in range(3):\n",
    "        i = frame\n",
    "        while i < len(seq) - 2:\n",
    "            codon = seq[i:i+3]\n",
    "            if codon == start_codon:\n",
    "                for j in range(i+3, len(seq) - 2, 3):\n",
    "                    stop = seq[j:j+3]\n",
    "                    if stop in stop_codons:\n",
    "                        orf = seq[i:j+3]\n",
    "                        if len(orf) >= 100:\n",
    "                            orfs.append(orf)\n",
    "                        break\n",
    "            i += 3\n",
    "\n",
    "    total_orf_bases = sum(len(orf) for orf in orfs)\n",
    "    longest_orf = max([len(orf) for orf in orfs], default=0)\n",
    "    orf_coverage = 100 * total_orf_bases / len(seq) if len(seq) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"orf_count\": len(orfs),\n",
    "        \"longest_orf\": longest_orf,\n",
    "        \"orf_coverage_percent\": orf_coverage\n",
    "    }\n",
    "\n",
    "# Extract only selected features\n",
    "def extract_selected_features_to_csv(fasta_file, output_csv):\n",
    "    feature_list = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq = str(record.seq).upper()\n",
    "        features = {\n",
    "            \"ID\": record.id,\n",
    "            \"GC_Content\": gc_content(seq),\n",
    "        }\n",
    "        features.update(selected_4mer_frequencies(seq))\n",
    "        features.update(extract_orf_features(seq))\n",
    "        feature_list.append(features)\n",
    "\n",
    "    df = pd.DataFrame(feature_list)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"âœ… Selected features saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "fasta_train = \"/content/drive/MyDrive/Ragini_SNP/Susceptibel_fna_dataset - merged/test_sequences_sus_750.fasta\"\n",
    "output_train = \"/content/drive/MyDrive/Ragini_SNP/Susceptibel_fna_dataset - merged/test_sequences_sus_750.csv\"\n",
    "\n",
    "extract_selected_features_to_csv(fasta_train, output_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17c957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
